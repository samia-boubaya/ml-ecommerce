{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc4f7e7",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# ü§ñ 05 - MACHINE LEARNING ü§ñ\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2edb9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### üìÇ IMPORTs\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: red;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8cd1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy in C:\\Program Files\\Python311\\Lib\\site-packages (from xgboost) (2.4.2)\n",
      "Requirement already satisfied: scipy in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from xgboost) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# install xgboost if not already installed\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677ec572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: shap in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (0.50.0)\n",
      "Requirement already satisfied: numpy>=2 in C:\\Program Files\\Python311\\Lib\\site-packages (from shap) (2.4.2)\n",
      "Requirement already satisfied: scipy in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from shap) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from shap) (1.8.0)\n",
      "Requirement already satisfied: pandas in C:\\Program Files\\Python311\\Lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in C:\\Program Files\\Python311\\Lib\\site-packages (from shap) (26.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from shap) (0.64.0)\n",
      "Requirement already satisfied: cloudpickle in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from shap) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from shap) (4.12.2)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from numba>=0.54->shap) (0.46.0)\n",
      "Requirement already satisfied: colorama in C:\\Program Files\\Python311\\Lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in C:\\Program Files\\Python311\\Lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in C:\\Program Files\\Python311\\Lib\\site-packages (from pandas->shap) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in C:\\Program Files\\Python311\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from scikit-learn->shap) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages (from scikit-learn->shap) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "# install shap if not already installed\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6fe5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in C:\\Program Files\\Python311\\Lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: pandas in C:\\Program Files\\Python311\\Lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in C:\\Program Files\\Python311\\Lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in C:\\Program Files\\Python311\\Lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in C:\\Program Files\\Python311\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# install numpy and pandas if not already installed\n",
    "!pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a91539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d34ed",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# 0Ô∏è‚É£ Load + Preprocess Dataset + Test\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e1367",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## üìä STEP 1 ‚Äî Load Data\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7511bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load the clean dataset\n",
    "df = pd.read_csv(\"../data/processed/online_shoppers_intention_07_encoded.csv\")\n",
    "\n",
    "# For consistency with code:\n",
    "    # X = features without the target variable\n",
    "    # y = target variable \"revenue\"\n",
    "\n",
    "# drop the target variable \"revenue\" from the features\n",
    "X = df.drop(\"revenue\", axis=1)\n",
    "\n",
    "# target variable \"revenue\" is already binary (0 and 1) \n",
    "y=df[\"revenue\"]\n",
    "\n",
    "# if it's not already in that format (it should be, but just to be safe)\n",
    "# y = df[\"revenue\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b324a0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## üßπ STEP 2 ‚Äî Preprocessing\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f24e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 74 numerical features and 0 categorical features for preprocessing.\n",
      "Numerical features: ['admin', 'admin_duration', 'info', 'info_duration', 'prod_related', 'prod_related_duration', 'bounce_rate', 'exit_rate', 'page_value', 'special_day', 'weekend', 'month_Aug', 'month_Dec', 'month_Feb', 'month_Jul', 'month_June', 'month_Mar', 'month_May', 'month_Nov', 'month_Oct', 'month_Sep', 'visitor_type_New_Visitor', 'visitor_type_Other', 'visitor_type_Returning_Visitor', 'browser_1', 'browser_2', 'browser_3', 'browser_4', 'browser_5', 'browser_6', 'browser_7', 'browser_8', 'browser_9', 'browser_10', 'browser_11', 'browser_12', 'browser_13', 'os_1', 'os_2', 'os_3', 'os_4', 'os_5', 'os_6', 'os_7', 'os_8', 'region_1', 'region_2', 'region_3', 'region_4', 'region_5', 'region_6', 'region_7', 'region_8', 'region_9', 'traffic_type_1', 'traffic_type_2', 'traffic_type_3', 'traffic_type_4', 'traffic_type_5', 'traffic_type_6', 'traffic_type_7', 'traffic_type_8', 'traffic_type_9', 'traffic_type_10', 'traffic_type_11', 'traffic_type_12', 'traffic_type_13', 'traffic_type_14', 'traffic_type_15', 'traffic_type_16', 'traffic_type_17', 'traffic_type_18', 'traffic_type_19', 'traffic_type_20']\n",
      "Categorical features: []\n",
      "Defined two separate preprocessors: one with scaling for models that require it, and one without scaling for tree-based models.\n"
     ]
    }
   ],
   "source": [
    "# identify numerical and categorical features for preprocessing\n",
    "\n",
    "    # - NUMERICAL features will be scaled for models that require it (Logistic Regression, SVM, KNN), \n",
    "    # but not for tree-based models (Decision Tree, Random Forest, XGBoost)\n",
    "numeric_features = X.select_dtypes(include=['int64','float64']).columns\n",
    "\n",
    "    # - CATEGORICAL features will be one-hot encoded for all models\n",
    "    # we include bool type as well since we have some boolean features that should be treated as categorical\n",
    "categorical_features = X.select_dtypes(include=['object','bool']).columns\n",
    "\n",
    "print(f\"Identified {len(numeric_features)} numerical features and {len(categorical_features)} categorical features for preprocessing.\")\n",
    "print(f\"Numerical features: {list(numeric_features)}\")\n",
    "print(f\"Categorical features: {list(categorical_features)}\")\n",
    "\n",
    "\n",
    "# define two separate preprocessors:  ------------------------------------------------    \n",
    "    # - one with scaling for models that require it\n",
    "preprocessor_scaled = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "    # - one without scaling for tree-based models\n",
    "preprocessor_tree = ColumnTransformer([\n",
    "    ('num', 'passthrough', numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "print(\"Defined two separate preprocessors: one with scaling for models that require it, and one without scaling for tree-based models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c639d9",
   "metadata": {},
   "source": [
    "```text\n",
    "the num vs cat is wrong don't use\n",
    "it's just not useable\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472a140",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## ‚úÇÔ∏è STEP 3 ‚Äî Train/Test Split\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fdb60",
   "metadata": {},
   "source": [
    "| Variable         | Description                                      | Role in Modeling                 |\n",
    "|------------------|--------------------------------------------------|-----------------------------------|\n",
    "| `X`                | session features                                 | Independent variables (input)     |\n",
    "| `y`                | Revenue outcome (purchase intention)             | Dependent variable (target)       |\n",
    "| `features_train`  | Training feature set used to train models             | Model training data                |\n",
    "| `features_test`   | Testing feature set used to evaluate model performance | Model evaluation data             |\n",
    "| `target_train`    | Training target labels  | Supervised learning - Binary target (train)|\n",
    "| `target_test`     | Testing target labels      | Supervised learning - Binary target (test) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581d5a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[features_train] saved to CSV file.\n",
      "[features_test] saved to CSV file.\n",
      "[target_train] saved to CSV file.\n",
      "[target_test] saved to CSV file.\n"
     ]
    }
   ],
   "source": [
    "# Split the data into:\n",
    "# - Training set\n",
    "# - Test set\n",
    "# Using stratify to maintain class balance\n",
    "\n",
    "(\n",
    "    features_train,     # features for training\n",
    "    features_test,      # features for testing\n",
    "    target_train,       # target for training\n",
    "    target_test         # target for testing\n",
    ") = train_test_split(\n",
    "    X, # features without the target variable \"revenue\"\n",
    "    y, # target variable \"revenue\"\n",
    "    test_size=0.2,      # 20% test set, 80% train set\n",
    "    stratify=y,         # maintain class balance in splits\n",
    "    random_state=42     # for reproducibility, we can choose any integer as the random state\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# save the train and test sets to CSV files for later use in modeling\n",
    "features_train.to_csv(\"../data/processed/features_train.csv\", index=False)\n",
    "print(\"[features_train] saved to CSV file.\")\n",
    "\n",
    "features_test.to_csv(\"../data/processed/features_test.csv\", index=False)\n",
    "print(\"[features_test] saved to CSV file.\")\n",
    "\n",
    "\n",
    "\n",
    "# save the target variable for train and test sets to CSV files for later use in modeling\n",
    "target_train.to_csv(\"../data/processed/target_train.csv\", index=False)\n",
    "print(\"[target_train] saved to CSV file.\")\n",
    "\n",
    "target_test.to_csv(\"../data/processed/target_test.csv\", index=False)\n",
    "print(\"[target_test] saved to CSV file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcc7c7",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# 1Ô∏è‚É£ BASELINE\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4937544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Class imbalance ratio (negative:positive) in training set: 5.40\n",
      "----------------------------------------------------------------------\n",
      "Class distribution in entire dataset:\n",
      "revenue\n",
      "0    10297\n",
      "1     1908\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution percentages in entire dataset:\n",
      "revenue\n",
      "0    84.367063\n",
      "1    15.632937\n",
      "Name: proportion, dtype: float64\n",
      "----------------------------------------------------------------------\n",
      "Class distribution in training set:\n",
      "revenue\n",
      "0    8238\n",
      "1    1526\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution percentages in training set:\n",
      "revenue\n",
      "0    84.371159\n",
      "1    15.628841\n",
      "Name: proportion, dtype: float64\n",
      "----------------------------------------------------------------------\n",
      "Class distribution in test set:\n",
      "revenue\n",
      "0    2059\n",
      "1     382\n",
      "Name: count, dtype: int64\n",
      "/nClass distribution percentages in test set:\n",
      "revenue\n",
      "0    84.350676\n",
      "1    15.649324\n",
      "Name: proportion, dtype: float64\n",
      "----------------------------------------------------------------------\n",
      "Class imbalance ratio (negative:positive) in training set: 5.40\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For consistency in code team collaboration \n",
    "# assign:  X_train,  X_test,  y_train,  y_test \n",
    "X_train = features_train\n",
    "X_test = features_test\n",
    "y_train = target_train\n",
    "y_test = target_test\n",
    "\n",
    "print(70*\"-\")\n",
    "\n",
    "# calculate the class imbalance ratio for the training set to use in XGBoost's scale_pos_weight parameter\n",
    "ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Class imbalance ratio (negative:positive) in training set: {ratio:.2f}\")\n",
    "    # This ratio will be used in the XGBoost model to help it handle the class imbalance effectively.\n",
    "    # A ratio greater than 1 indicates that the negative class (0) is more prevalent than the positive class (1),  which is common in many real-world datasets. \n",
    "    # By setting scale_pos_weight to this ratio, we can help XGBoost give more attention to the minority class during training.\n",
    "\n",
    "print(70*\"-\")\n",
    "\n",
    "# distribution ENTIRE dataset\n",
    "print(\"Class distribution in entire dataset:\")\n",
    "print(pd.concat([y_train, y_test]).value_counts())\n",
    "# percentage ENTIRE dataset\n",
    "print(\"\\nClass distribution percentages in entire dataset:\")\n",
    "print(pd.concat([y_train, y_test]).value_counts(normalize=True) * 100)\n",
    "print(70*\"-\")\n",
    "\n",
    "# distribution TRAIN set\n",
    "print(\"Class distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "# percentage TRAIN set\n",
    "print(\"\\nClass distribution percentages in training set:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "print(70*\"-\")\n",
    "\n",
    "\n",
    "# distribution TEST set\n",
    "print(\"Class distribution in test set:\")\n",
    "print(y_test.value_counts())\n",
    "# percentage TEST set\n",
    "print(\"/nClass distribution percentages in test set:\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "print(70*\"-\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Class imbalance ratio (for XGBoost) ---------------------------------------------------------------------------\n",
    "pos_count = (y_train == 1).sum()\n",
    "neg_count = (y_train == 0).sum()\n",
    "\n",
    "if pos_count == 0:\n",
    "    ratio = 1\n",
    "else:\n",
    "    ratio = neg_count / pos_count\n",
    "\n",
    "print(f\"Class imbalance ratio (negative:positive) in training set: {ratio:.2f}\")\n",
    "print(70 * \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc2615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score Mean and Standard Deviation across folds for the last model:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cross-Validation F1 Mean & Std  -------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# F1 Score Mean and Standard Deviation across folds for the last model\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mF1 Score Mean and Standard Deviation across folds for the last model:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(\u001b[43mf1_list\u001b[49m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# mean of F1 scores across the 5 folds\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStandard Deviation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.std(f1_list)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# standard deviation of F1 scores across the 5 folds\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'f1_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Cross-Validation F1 Mean & Std  -------------------------------------------------------------------------------------------\n",
    "\n",
    "# F1 Score Mean and Standard Deviation across folds for the last model\n",
    "print(\"F1 Score Mean and Standard Deviation across folds for the last model:\")\n",
    "print(f\"Mean: {np.mean(f1_list):.4f}\") # mean of F1 scores across the 5 folds\n",
    "print(f\"Standard Deviation: {np.std(f1_list):.4f}\") # standard deviation of F1 scores across the 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c35051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Class imbalance ratio (for XGBoost)\n",
    "# ==========================================\n",
    "pos_count = (y_train == 1).sum()\n",
    "neg_count = (y_train == 0).sum()\n",
    "ratio = neg_count / pos_count if pos_count != 0 else 1\n",
    "\n",
    "print(f\"Imbalance ratio (neg:pos) = {ratio:.2f}\")\n",
    "print(70 * \"-\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Define Models\n",
    "# ==========================================\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=ratio,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Cross-validation setup\n",
    "# ==========================================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Train + Evaluate\n",
    "# ==========================================\n",
    "for name, model in models.items():\n",
    "\n",
    "    # ---- Fit on training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ---- Predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # ---- Probabilities (for AUC metrics)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_test)\n",
    "\n",
    "    # ---- Metrics (Test Set)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    pr_auc = average_precision_score(y_test, y_proba)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # ---- Cross-validation (F1)\n",
    "    cv_scores = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=\"f1\"\n",
    "    )\n",
    "\n",
    "    mean_cv = cv_scores.mean()\n",
    "    std_cv = cv_scores.std()\n",
    "\n",
    "    # ---- Store Results\n",
    "    results.append([\n",
    "        name, precision, recall, f1,\n",
    "        (y_test == 1).sum(),   # Support (positive class)\n",
    "        pr_auc, roc_auc,\n",
    "        mean_cv, std_cv,\n",
    "        mcc,\n",
    "        tp, tn, fp, fn\n",
    "    ])\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Create Results Table\n",
    "# ==========================================\n",
    "columns = [\n",
    "    \"Model\", \"Precision\", \"Recall\", \"F1 Score\",\n",
    "    \"Support\", \"PR-AUC\", \"ROC-AUC\",\n",
    "    \"Mean (CV F1)\", \"Std (CV F1)\",\n",
    "    \"MCC\",\n",
    "    \"TP\", \"TN\", \"FP\", \"FN\"\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "print(results_df.sort_values(by=\"F1 Score\", ascending=False))\n",
    "print(70 * \"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3883ba0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## üìê STEP 4 ‚Äî Define Models\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d273231f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the following models with appropriate preprocessing and class imbalance handling:\n",
      " - Logistic Regression\n",
      " - Linear SVM\n",
      " - KNN\n",
      " - Decision Tree\n",
      " - Random Forest\n",
      " - XGBoost\n",
      " - AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# define a dictionary of models with appropriate preprocessing and class imbalance handling ------------------------------------------\n",
    "models = {\n",
    "\n",
    "    # Logistic Regression can handle class imbalance by setting class_weight='balanced',\n",
    "    # which will automatically adjust weights inversely proportional to class frequencies.\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        (\"prep\", preprocessor_scaled),\n",
    "        (\"model\", LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "    ]),\n",
    "    \n",
    "    # Linear SVM can handle class imbalance by setting class_weight='balanced', \n",
    "    # which will automatically adjust weights inversely proportional to class frequencies.\n",
    "    \"Linear SVM\": Pipeline([\n",
    "        (\"prep\", preprocessor_scaled),\n",
    "        (\"model\", SVC(kernel='linear', class_weight='balanced', probability=True))\n",
    "    ]),\n",
    "    \n",
    "    # KNN doesn't have a built-in way to handle class imbalance, but it can still be effective.\n",
    "    # We will use the preprocessor with scaling for KNN as well, since KNN is sensitive to feature scales.\n",
    "    \"KNN\": Pipeline([\n",
    "        (\"prep\", preprocessor_scaled),\n",
    "        (\"model\", KNeighborsClassifier())\n",
    "    ]),\n",
    "    \n",
    "    # Decision Tree can handle class imbalance by setting class_weight='balanced',\n",
    "    # which will automatically adjust weights inversely proportional to class frequencies.\n",
    "    \"Decision Tree\": Pipeline([\n",
    "        (\"prep\", preprocessor_tree),\n",
    "        (\"model\", DecisionTreeClassifier(class_weight='balanced'))\n",
    "    ]),\n",
    "    \n",
    "    # Random Forest can handle class imbalance by setting class_weight='balanced', \n",
    "    # which will automatically adjust weights inversely proportional to class frequencies.\n",
    "    \"Random Forest\": Pipeline([\n",
    "        (\"prep\", preprocessor_tree),\n",
    "        (\"model\", RandomForestClassifier(class_weight='balanced'))\n",
    "    ]),\n",
    "    \n",
    "    # XGBoost has a built-in way to handle class imbalance using the scale_pos_weight parameter.\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"prep\", preprocessor_tree),\n",
    "        (\"model\", XGBClassifier(scale_pos_weight=ratio, eval_metric='logloss'))\n",
    "    ]),\n",
    "\n",
    "    # AdaBoost doesn't have a built-in way to handle class imbalance, but it can still be effective. \n",
    "    # We will use the preprocessor without scaling for AdaBoost as well.\n",
    "    \"AdaBoost\": Pipeline([\n",
    "        (\"prep\", preprocessor_tree),\n",
    "        (\"model\", AdaBoostClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"Defined the following models with appropriate preprocessing and class imbalance handling:\")\n",
    "for model_name in models.keys():\n",
    "    print(f\" - {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=5000))\n",
    "    ]),\n",
    "    \n",
    "    \"Linear SVM\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"linear\", probability=True))\n",
    "    ]),\n",
    "    \n",
    "    \"KNN\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ]),\n",
    "\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247cea9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## ‚ö° STEP 5 ‚Äî  Run Baseline CV Comparison\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a99ab92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sboub\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Define Models------------------------------------------------------------------------------------------------\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# Cross Validation Setup------------------------------------------------------------------------------------------------\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop Through Models------------------------------------------------------------------------------------------------\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    roc_list = []\n",
    "    pr_list = []\n",
    "    mcc_list = []\n",
    "\n",
    "    tp_total = tn_total = fp_total = fn_total = 0\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Probabilities for AUC\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        precision_list.append(precision_score(y_test, y_pred))\n",
    "        recall_list.append(recall_score(y_test, y_pred))\n",
    "        f1_list.append(f1_score(y_test, y_pred))\n",
    "        roc_list.append(roc_auc_score(y_test, y_proba))\n",
    "        pr_list.append(average_precision_score(y_test, y_proba))\n",
    "        mcc_list.append(matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        tp_total += tp\n",
    "        tn_total += tn\n",
    "        fp_total += fp\n",
    "        fn_total += fn\n",
    "\n",
    "    results.append([\n",
    "        name,\n",
    "        np.mean(precision_list),# Precision \n",
    "        np.mean(recall_list),   # Recall\n",
    "        np.mean(f1_list),       # F1 Score\n",
    "        np.sum(y == 1),         # Support (positive class)\n",
    "        np.mean(pr_list),       # PR-AUC\n",
    "        np.mean(roc_list),      # ROC-AUC\n",
    "        np.mean(f1_list),       # Performance (using F1)\n",
    "        np.std(f1_list),        # Standard deviation\n",
    "        np.mean(mcc_list),      # MCC\n",
    "        tp_total, tn_total, fp_total, fn_total # Confusion Matrix totals\n",
    "    ])\n",
    "\n",
    "\n",
    "# Create Results Table ------------------------------------------------------------------------------------------------\n",
    "\n",
    "columns = [\n",
    "    \"Model\", \"Precision\", \"Recall\", \"F1 Score\",\n",
    "    \"Support\", \"PR-AUC\", \"ROC-AUC\",\n",
    "    \"Mean (F1)\", \"Std (F1)\",\n",
    "    \"MCC\", \"TP\", \"TN\", \"FP\", \"FN\"\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation to evaluate the models using ROC AUC as the scoring metric, which is appropriate for imbalanced classification problems\n",
    "cv_results = {\n",
    "    \"KNN\": cross_val_score(models[\"KNN\"], X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='roc_auc'),\n",
    "    \"Logistic Regression\": cross_val_score(models[\"Logistic Regression\"], X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='roc_auc'),\n",
    "    \"Linear SVM\": cross_val_score(models[\"Linear SVM\"], X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='roc_auc'),\n",
    "    \"Decision Tree\": cross_val_score(models[\"Decision Tree\"], X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='roc_auc'),\n",
    "    \"Random Forest\": cross_val_score(models[\"Random Forest\"], X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='roc_auc'),\n",
    "    \"XGBoost\": cross_val_score(models[\"XGBoost\"], X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='roc_auc'),\n",
    "    \"AdaBoost\": cross_val_score(models[\"AdaBoost\"], X_train, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='roc_auc')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84989ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f87ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stratified k-fold cross-validation to evaluate baseline performance of each model\n",
    "# cv = cross validation strategy that maintains class balance in each fold, which is important for imbalanced datasets like ours.\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# store mean ROC-AUC scores for each model in results dictionary\n",
    "results = {\n",
    "    # after cross-validation:\n",
    "    # the model names as keys and their mean ROC-AUC scores as values \n",
    "    \"Logistic Regression\": None,\n",
    "    \"Linear SVM\": None,\n",
    "    \"KNN\": None,\n",
    "    \"Decision Tree\": None,\n",
    "    \"Random Forest\": None,\n",
    "    \"XGBoost\": None,\n",
    "    \"AdaBoost\": None\n",
    "}\n",
    "\n",
    "# loop through each model, perform cross-validation, and store the mean ROC-AUC score\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train,\n",
    "                             cv=cv, scoring='roc_auc')\n",
    "    results[name] = scores.mean()\n",
    "\n",
    "# create a DataFrame to display the results in a sorted manner\n",
    "baseline_results = pd.DataFrame.from_dict(results, orient='index',\n",
    "                                          columns=['ROC-AUC']).sort_values(by=\"ROC-AUC\", ascending=False)\n",
    "\n",
    "# display the baseline results\n",
    "print(\"Baseline ROC-AUC scores for each model:\")\n",
    "display(baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221bfb9b",
   "metadata": {},
   "source": [
    "---\n",
    "#### NOTES\n",
    "üëâ Best model by ROC-AUC: XGBoost (0.9275)\n",
    "- It has the highest ability to rank positive cases above negative cases.\n",
    "\n",
    "‚ö†Ô∏è Is ROC-AUC enough for imbalanced data? Short answer: No, it is not enough.\n",
    "- ROC-AUC can be misleading for imbalanced datasets because:\n",
    "    - It evaluates performance across all classification thresholds.\n",
    "    - It gives equal importance to True Positive Rate (TPR) and False Positive Rate (FPR).\n",
    "    - When negatives heavily outnumber positives, the FPR can look artificially small, inflating ROC-AUC.\n",
    "    - In highly imbalanced data, a model can achieve high ROC-AUC but still perform poorly at identifying the minority class.\n",
    "\n",
    "üîé For imbalanced datasets, prioritize:\n",
    "\n",
    "1Ô∏è‚É£ Precision-Recall AUC (PR-AUC) ‚≠ê (Very Important)\n",
    "- More informative when the positive class is rare.\n",
    "- Focuses only on the positive class performance.\n",
    "\n",
    "2Ô∏è‚É£ F1-score\n",
    "- Harmonic mean of precision and recall.\n",
    "- Good when you need balance between false positives and false negatives.\n",
    "\n",
    "3Ô∏è‚É£ Recall (Sensitivity)\n",
    "- Important if missing positives is costly (e.g., fraud, disease).\n",
    "\n",
    "4Ô∏è‚É£ Confusion Matrix\n",
    "- Shows actual classification behavior at your chosen threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f190c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cross_validation_metrics = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'pr_auc': 'average_precision',  # PR-AUC\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # Cross-validated metrics\n",
    "    cv_scores = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cross_validation_metrics,\n",
    "        scoring=scoring,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    # Predictions for confusion matrix\n",
    "    y_pred = cross_val_predict(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cross_validation_metrics\n",
    "    )\n",
    "    \n",
    "    results[name] = {\n",
    "        \"ROC-AUC\": cv_scores['test_roc_auc'].mean(),\n",
    "        \"PR-AUC\": cv_scores['test_pr_auc'].mean(),\n",
    "        \"Accuracy\": cv_scores['test_accuracy'].mean(),\n",
    "        \"Precision\": cv_scores['test_precision'].mean(),\n",
    "        \"Recall\": cv_scores['test_recall'].mean(),\n",
    "        \"F1-score\": cv_scores['test_f1'].mean(),\n",
    "        \"Confusion Matrix\": confusion_matrix(y_train, y_pred)\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}:\\n{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0d852",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## üèÜ STEP 6 ‚Äî  Select TOP 3 Models\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c397a06",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### MODELS - METRICS\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: pink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import metrics for evaluation on the test set\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "# define a function to evaluate a model on the test set and return a dictionary of metrics\n",
    "def evaluate_model(model, model_name):\n",
    "    # Fit model\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(features_test)\n",
    "    y_prob = model.predict_proba(features_test)[:, 1]\n",
    "    \n",
    "    # Metrics (Buy = positive class = 1)\n",
    "    accuracy = accuracy_score(target_test, y_pred)\n",
    "    precision_buy = precision_score(target_test, y_pred)\n",
    "    recall_buy = recall_score(target_test, y_pred)\n",
    "    f1_buy = f1_score(target_test, y_pred)\n",
    "    roc_auc = roc_auc_score(target_test, y_prob)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": round(accuracy, 3),\n",
    "        \"Precision (Buy)\": round(precision_buy, 3),\n",
    "        \"Recall (Buy)\": round(recall_buy, 3),\n",
    "        \"F1-score (Buy)\": round(f1_buy, 3),\n",
    "        \"ROC-AUC\": round(roc_auc, 3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a274e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "results.append(evaluate_model(knn_model, \"KNN\"))\n",
    "results.append(evaluate_model(logreg_model, \"Logistic Regression\"))\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nModel Comparison\")\n",
    "print(comparison_df.sort_values(by=\"ROC-AUC\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d28f3f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### CONFUSION MATRIX\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: pink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(target_test, y_pred)\n",
    "\n",
    "cm_table = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Actual Not Buy\", \"Actual Buy\"],\n",
    "    columns=[\"Pred Not Buy\", \"Pred Buy\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nConfusion Matrix - {model_name}\")\n",
    "print(cm_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d30fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_2 = confusion_matrix(y_test, y_train)\n",
    "\n",
    "cm_table_2 = pd.DataFrame(\n",
    "    cm_2,\n",
    "    index=[\"Actual Not Buy\", \"Actual Buy\"],\n",
    "    columns=[\"Pred Not Buy\", \"Pred Buy\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nConfusion Matrix - {model_name}\")\n",
    "print(cm_table_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd29c25",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# 2Ô∏è‚É£ DEEP TUNING TOP 3 MODELS\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb42d9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## MODEL 1:\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82644fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0406f64d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## MODEL 2:\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e86a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12792b37",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## MODEL 3:\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41732a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea44caed",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# 3Ô∏è‚É£ FINAL EVALUATION\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with best_model from \"DEEP TUNING TOP 3\" phase\n",
    "# for example, if Random Forest was the best model after tuning, you would set:\n",
    "best_model = best_rf\n",
    "\n",
    "# fit the best model on the entire training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate on test set\n",
    "# get predicted probabilities for ROC-AUC and predicted classes for other metrics\n",
    "\n",
    "# y_pred will be used for F1 score, confusion matrix, and classification report\n",
    "y_pred = best_model.predict(X_test)\n",
    "# y_prob will be used for ROC-AUC\n",
    "y_prob = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# print evaluation metrics\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "# print F1 score\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "# print confusion matrix \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad98567",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# üèÅ Final Model Selection Criteria\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d260d",
   "metadata": {},
   "source": [
    "Choose model with:\n",
    "- Highest CV ROC-AUC\n",
    "- Good F1\n",
    "- Good Recall (important for purchase detection)\n",
    "- Stable performance (low variance across folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ef7c0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# üìä PLOTS\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a1c7be",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 01 - ROC Curves (Compare top 3 models)\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e055fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the plot version you want to add to main notebook here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9027dfcd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 01 - ROC Curves - Model 1\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: pink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20400fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "205b3894",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 01 - ROC Curves - Model 2\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: pink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d3ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00852980",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 01 - ROC Curves - Model 3\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: pink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712840c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94e5fc13",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 02 - Adjust Decision Threshold\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43959e59",
   "metadata": {},
   "source": [
    "- **Instead of 0.5:**\n",
    "- **This should improve recall.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4163549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the plot version you want to add to main notebook here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41bf65",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 02 -Adjust Decision Threshold - V1\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: pink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238bb984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc7bfbc2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 02 - Adjust Decision Threshold - V2\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: left;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: left;\n",
    "    color: pink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff12334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "439ea413",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 03 - Feature Importance\n",
    "\n",
    "\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h2 {\n",
    "    text-align: center;\n",
    "    color: hotpink;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<style>\n",
    "h4 {\n",
    "    text-align: center;\n",
    "    color: black;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0449583",
   "metadata": {},
   "source": [
    "- **For RF / XGBoost: Use  `.feature_importances_`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
